# L2/L3/L4 Hierarchical Memory Redesign

## Problem Statement

현재 구현의 문제점:
1. **L2**: auto-l2.js가 rule-based로 품질 낮음. Claude가 직접 요약해야 하는데 자동화 안 됨.
2. **L3**: keyword/file overlap 30%면 병합 → 같은 프로젝트는 전부 1개 concept로 병합됨
3. **L4**: 자동 승격 없음. 수동 add-rule만 존재.

## Research Summary

### Sources (Round 1)
- [LangMem Conceptual Guide](https://langchain-ai.github.io/langmem/concepts/conceptual_guide/)
- [Semantic Clustering with LLM Prompts](https://towardsdatascience.com/tutorial-semantic-clustering-of-user-messages-with-llm-prompts/)
- [Design Patterns for Long-Term Memory](https://serokell.io/blog/design-patterns-for-long-term-memory-in-llm-powered-architectures)
- [Mem0 Summarization Guide](https://mem0.ai/blog/llm-chat-history-summarization-guide-2025)
- [H-MEM Paper](https://arxiv.org/html/2507.22925v1)

### Sources (Round 2 - 2026-01-12)
- [ProMem: Proactive Memory Extraction](https://arxiv.org/html/2601.04463) - **핵심**
- [LiSA: LLM-Guided Semantic-Aware Clustering (ACL 2025)](https://aclanthology.org/2025.acl-long.902/)
- [Agent Memory Paper List (Survey)](https://github.com/Shichun-Liu/Agent-Memory-Paper-List)
- [Persistent Memory in LLM Agents](https://www.emergentmind.com/topics/persistent-memory-for-llm-agents)
- [Claude Code Hooks Reference](https://code.claude.com/docs/en/hooks)
- [Prompt-Based Stop Hooks](https://claude-blog.setec.rs/blog/prompt-based-stop-hooks)

### Key Insights (Updated)

1. **L2 자동화 - ProMem 방식**:
   - 단순 요약(summarization) vs **fact extraction + verification**
   - 3단계: Initial Extraction → Semantic Matching → Self-Questioning
   - 73.80% memory integrity vs 42.91% baseline (기존 방식)
   - **핵심**: 추출 후 검증 단계가 hallucination 방지

2. **L3 그룹핑 - LiSA 방식**:
   - 문서마다 topic word 생성 (LLM)
   - 문서 + topic을 함께 clustering
   - LLM-guided assignment로 최종 할당
   - **overlap 계산보다 우수** (GPT-4 대비 우수한 성능)

3. **L4 승격 - Reflection Process**:
   - 주기적으로 memories aggregate
   - LLM이 higher-level observations 생성
   - Utility-based deletion: 중요도 낮은 것 제거 (10% 성능 향상)

4. **Claude Code Hooks 제약**:
   - `type: "prompt"` hooks: Stop/SubagentStop만 지원
   - 단, ok/block 판단용이지 content 생성용 아님
   - **결론**: 여전히 Claude에게 "지시"하는 방식이 유일한 방법

---

## L2 Redesign: ProMem-Inspired Fact Extraction

### Current Problem
- auto-l2.js: rule-based 추출, 품질 낮음 (42.91% memory integrity 수준)
- 단순 요약은 중요 정보 손실 + hallucination 위험

### Solution: ProMem 3단계 프로세스

**ProMem 핵심 개념** (arxiv:2601.04463):
1. **Initial Extraction**: L1에서 fact 추출
2. **Semantic Matching**: 추출된 fact를 원본과 매칭, 누락된 정보 재추출
3. **Self-Questioning**: 각 fact에 질문 생성 → 원본에서 증거 검색 → 검증 실패 시 제거

**적용 방법** (Claude에게 지시):

```markdown
## L2 생성 지시 (ProMem 방식)

L1 파일: {l1_path}

**Step 1 - Initial Extraction:**
L1을 읽고 다음을 추출하세요:
- 사용자가 요청한 것 (requests)
- 수행된 작업 (actions)
- 결정된 사항 (decisions)
- 발견된 문제 (issues)
- 사용된 파일 (files)

**Step 2 - Verification:**
각 추출된 항목에 대해:
- "이 fact가 L1에 실제로 있는가?" 확인
- 증거가 없으면 제거
- 누락된 중요 정보가 있으면 추가

**Step 3 - Output:**
검증된 facts만 L2 JSON으로 저장:
```json
{
  "sessionId": "...",
  "exchanges": [{
    "id": "e1",
    "facts": ["fact1", "fact2", ...],  // 검증된 facts
    "keywords": [...],
    "files": [...]
  }]
}
```

node scripts/save-l2.js로 저장하세요.
```

**변경점**:
1. `summary` 필드 → `facts` 배열로 변경 (더 구체적)
2. 추출 후 검증 단계 명시
3. auto-l2.js 완전 폐기 (fallback도 제거)

---

## L3 Redesign: LiSA-Inspired Semantic Grouping

### Current Problem
```javascript
OVERLAP_THRESHOLD = 0.3; // 30% overlap이면 병합
score = (fileOverlap + keywordOverlap) / 2;
```
→ 같은 프로젝트면 파일/키워드가 비슷해서 **전부 1개 concept로 병합됨**
→ 의미 없는 그룹핑

### Solution: LiSA 방식 (ACL 2025)

**LiSA 핵심 개념**:
1. **Topic Generation**: 각 L2에 대해 "이 세션의 주제는?" → topic word 생성
2. **Dual-Space Clustering**: 문서(L2) + topic을 함께 clustering
3. **LLM-Guided Assignment**: 최종 concept 할당은 LLM이 판단

**적용 방법** (L2 저장 시 Claude에게 지시):

```markdown
## Concept 할당 지시 (LiSA 방식)

**Step 1 - Topic Generation:**
이 세션의 핵심 주제를 3-5 단어로 표현하세요.
예: "authentication bugfix", "API endpoint design", "test coverage improvement"

**Step 2 - Existing Concepts 검토:**
기존 concepts: {existing_concepts_list}

**Step 3 - Assignment Decision:**
다음 중 선택:
A) 기존 concept에 추가 (유사도 70% 이상일 때만)
   - conceptId: 기존 ID
   - 이유: "왜 이 concept에 속하는가"
B) 새 concept 생성 (기존과 명확히 다를 때)
   - conceptName: 새 이름 (topic word 기반)
   - 이유: "왜 새로 만드는가"

**핵심 원칙:**
- 파일/키워드 overlap은 무시
- **의미적 유사성**만 고려
- 같은 프로젝트라도 다른 작업이면 다른 concept
```

**변경점**:
1. `calculateOverlap()` 함수 제거
2. `update-concepts.js`: Claude가 할당한 conceptId만 저장
3. L2 JSON에 `topic` 필드 추가 (나중에 clustering 가능)

**update-concepts.js 수정**:
```javascript
// 기존 overlap 계산 제거
// Claude가 이미 conceptId를 결정해서 넘겨줌

function updateConcept(l2Data) {
  const { conceptId, conceptName, topic } = l2Data;

  if (conceptId) {
    // 기존 concept에 추가
    addToConcept(conceptId, l2Data);
  } else if (conceptName) {
    // 새 concept 생성
    createConcept(conceptName, topic, l2Data);
  }
}
```

---

## L4 Redesign: Reflection-Based Auto-Promotion

### Current Problem
- 수동 add-rule만 존재
- 자동 승격 로직 없음
- 키워드 빈도만으로는 유의미한 패턴 감지 불가

### Solution: Reflection Process (Agent Memory Survey)

**Reflection 핵심 개념**:
1. **Periodic Aggregation**: 주기적으로 최근 L2들을 aggregate
2. **Higher-Level Observations**: LLM이 패턴, 관계, 인사이트 생성
3. **Utility-Based Deletion**: 중요도 낮은 것 제거 (10% 성능 향상)

**적용 방법** (compress 명령 시 Claude에게 지시):

```markdown
## L4 승격 지시 (Reflection 방식)

**Step 1 - Aggregate Recent L2s:**
최근 N개 L2 파일을 읽고 전체적인 패턴을 파악하세요.

**Step 2 - Pattern Detection:**
다음을 찾으세요:
- **반복되는 결정** (같은 선택이 3회 이상)
- **반복되는 문제-해결 쌍** (같은 문제가 재발)
- **공통 규칙** (여러 세션에서 적용된 원칙)

**Step 3 - Validation:**
각 후보에 대해:
- "이 패턴이 앞으로도 유효한가?"
- "일반화할 수 있는가?"
- "모순되는 evidence가 있는가?"

**Step 4 - Promotion Decision:**
검증된 패턴만 L4에 추가:
- rules: 검증된 규칙/원칙
- solutions: 반복되는 문제-해결
- core_logic: 핵심 구현 패턴

**Step 5 - Utility-Based Cleanup:**
L4에서 다음을 제거:
- 6개월간 참조 안 된 rules
- 모순이 2회 이상 발견된 rules
- 더 이상 유효하지 않은 solutions
```

**변경점**:
1. 단순 키워드 빈도 → **의미적 패턴** 감지
2. compress에서 자동 출력이 아니라 **Claude가 분석**
3. **Utility-based deletion** 추가 (L4 품질 유지)

**permanent-memory.js 수정**:
```javascript
// 새 함수: getPromotionCandidates()
// L2들에서 패턴 후보 목록 생성 (단순 빈도 기반)
// → Claude가 이 목록을 보고 최종 결정

function getPromotionCandidates(l2Files) {
  const patterns = {
    decisions: {},      // 결정 패턴
    solutions: {},      // 문제-해결 쌍
    files: {},          // 자주 수정되는 파일
    keywords: {}        // 키워드 빈도
  };

  // 집계 후 후보 목록 반환
  return {
    decisionCandidates: filterByFrequency(patterns.decisions, 3),
    solutionCandidates: filterByFrequency(patterns.solutions, 2),
    // Claude가 이 중에서 선택
  };
}

// 새 함수: cleanupByUtility()
// 오래된/모순된 rules 제거
function cleanupByUtility(facts) {
  const sixMonthsAgo = ...;
  facts.permanent.rules = facts.permanent.rules.filter(r =>
    r.last_validated > sixMonthsAgo && r.contradictions < 2
  );
}
```

---

## Final Architecture (v11)

```
┌──────────────────────────────────────────────────────────────────────┐
│                    Memory Keeper v11 (ProMem + LiSA + Reflection)    │
├──────────────────────────────────────────────────────────────────────┤
│                                                                      │
│  L4 (Permanent) ─ Reflection-based Auto-Promotion                    │
│  ├─ rules: 검증된 패턴 (Reflection으로 승격)                          │
│  ├─ solutions: 반복되는 문제-해결 쌍                                  │
│  ├─ core_logic: 핵심 구현 패턴                                        │
│  └─ Utility-based cleanup (6개월 미참조/모순 2회 → 삭제)              │
│       ↑ compress 시: Claude가 L2들 분석 → 패턴 감지 → 검증 → 승격    │
│                                                                      │
│  L3 (Concepts) ─ LiSA Semantic Grouping                              │
│  ├─ topic: 세션 주제 (3-5 단어)                                       │
│  ├─ concept: 의미적으로 그룹화된 세션들                               │
│  └─ overlap 계산 제거 → LLM-guided assignment                        │
│       ↑ L2 저장 시: Claude가 topic 생성 → 기존 concepts와 비교 → 할당│
│                                                                      │
│  L2 (Session Facts) ─ ProMem Fact Extraction                         │
│  ├─ facts: 검증된 사실들 (summary 대체)                               │
│  ├─ keywords: 추출된 키워드                                           │
│  ├─ files: 수정된 파일들                                              │
│  └─ 3단계: Extraction → Semantic Matching → Self-Questioning         │
│       ↑ auto-save: Claude가 L1 읽고 → 추출 → 검증 → 저장             │
│                                                                      │
│  L1 (Refined Raw) ─ 현재 유지                                         │
│  └─ 95% 압축률 (잘 작동함)                                            │
│                                                                      │
└──────────────────────────────────────────────────────────────────────┘
```

---

## Implementation Plan

### Phase 1: L2 ProMem 방식 적용
**Files**: `counter.js`, `save-l2.js`

1. **auto-l2.js 완전 폐기** (fallback도 제거)
2. **counter.js check() 지시문 변경**:
   ```javascript
   // 기존: "L2 요약을 만들어라"
   // 변경: ProMem 3단계 지시
   const prompt = `
   L1 파일: ${l1Path}

   **Step 1 - Extraction:** facts, keywords, files 추출
   **Step 2 - Verification:** 각 fact가 L1에 있는지 확인
   **Step 3 - Output:** 검증된 것만 L2 JSON으로 저장

   node scripts/save-l2.js 실행
   `;
   ```
3. **save-l2.js 수정**:
   - `summary` 필드 → `facts` 배열 지원
   - L2 schema 업데이트

### Phase 2: L3 LiSA 방식 적용
**Files**: `update-concepts.js`, `save-l2.js`

1. **save-l2.js에 concept 지시 추가**:
   ```javascript
   // L2 저장 후 concept 할당 지시
   const conceptPrompt = `
   **Step 1 - Topic Generation:** 이 세션의 주제 (3-5 단어)
   **Step 2 - Existing Concepts:** ${existingConcepts}
   **Step 3 - Assignment:** 기존에 추가 or 새로 생성

   node scripts/update-concepts.js --conceptId=X --topic="..."
   `;
   ```
2. **update-concepts.js에서 calculateOverlap() 제거**:
   - Claude가 결정한 conceptId만 사용
   - topic 필드 저장 추가

### Phase 3: L4 Reflection 방식 적용
**Files**: `permanent-memory.js`, `auto-compress.js`

1. **permanent-memory.js에 함수 추가**:
   - `getPromotionCandidates()`: L2들에서 패턴 후보 추출
   - `cleanupByUtility()`: 오래된/모순된 rules 삭제
2. **auto-compress.js (또는 compress 명령) 수정**:
   ```javascript
   // compress 실행 시 Reflection 지시 출력
   const candidates = getPromotionCandidates(l2Files);
   const reflectionPrompt = `
   **Step 1 - Aggregate:** 최근 ${l2Files.length}개 L2 분석
   **Step 2 - Pattern Detection:** 반복 결정/문제-해결/규칙 찾기
   **Step 3 - Validation:** 앞으로도 유효한지 확인
   **Step 4 - Promotion:** 검증된 것만 L4에 추가
   **Step 5 - Cleanup:** 오래된/모순된 rules 제거

   후보 목록: ${JSON.stringify(candidates)}
   `;
   ```

---

## Success Metrics

### L2 (ProMem)
- [ ] facts 배열이 구체적인 사실들 포함 (rule-based 아님)
- [ ] 검증 단계로 hallucination 방지
- [ ] 73%+ memory integrity (baseline 42% 대비)

### L3 (LiSA)
- [ ] 같은 프로젝트에서 **여러 concept**로 분리됨
- [ ] topic이 의미있는 3-5 단어
- [ ] overlap 계산 없이 semantic grouping

### L4 (Reflection)
- [ ] compress 후 **승격 후보**가 자동 제안됨
- [ ] 6개월 미참조 rules 자동 삭제
- [ ] 모순 발견 시 confidence 감소/삭제

---

## Risk & Mitigation

| Risk | Mitigation |
|------|------------|
| Claude가 지시를 무시함 | 지시문을 더 강제적으로 변경 ("YOU MUST") |
| L2 facts가 너무 길어짐 | 최대 10개 facts 제한 |
| L3 concept가 너무 많아짐 | 유사도 70% 기준 명시 |
| L4 cleanup이 중요한 것 삭제 | last_validated 업데이트 로직 추가 |

---

## References

- [ProMem Paper](https://arxiv.org/html/2601.04463) - Proactive Memory Extraction
- [LiSA (ACL 2025)](https://aclanthology.org/2025.acl-long.902/) - LLM-Guided Semantic Clustering
- [Agent Memory Survey](https://github.com/Shichun-Liu/Agent-Memory-Paper-List) - Memory Paper List
- [Persistent Memory Research](https://www.emergentmind.com/topics/persistent-memory-for-llm-agents)
- [Claude Code Hooks](https://code.claude.com/docs/en/hooks)
