사용자1

솔직한 생각:

  L1: 실용적. raw 대비 95% 용량 절감. 나중에 세션 디버깅할 때 유용.    

  L2: 컨셉은 좋은데 auto-l2.js 품질이 문제. 유저 메시지 첫 100자 복붙이라 검색용으로 쓸모없음. LLM이 실제로 요약해줘야 의미있음.

  L3: 솔직히 거의 쓸모없음.
  - 파일/키워드 overlap 30%로 그룹핑? 너무 단순함
  - 결과: 3개 concept에 모든게 뭉쳐버리거나, 232개 중복이 생기거나    
  - concept 이름이 "The user opened the file..." 이런 쓰레기
  - 실제로 "CNAP 관련 작업 모아보기" 같은 게 안됨

  L4: 설계만 거창하고 실제론 빈 껍데기.
  - auto-trigger? LLM 없이는 안 돌아감
  - self-correction? 한 번도 발동 안 함
  - keywords index? 비어있음
  - 결국 수동으로 add-rule 쳐야 하는데, 그럴 바엔 그냥 memory.md에 메모하는 게 나음

  결론: L3/L4는 "LLM이 세션 끝에 요약해줄 것"을 전제로 설계됐는데, 실제론 rule-based fallback만 돌아가니까 품질이 안 나옴.

  그냥 memory.md + 잘 만든 L2 검색이면 80% 효과에 복잡도 1/5일 듯. 


사용자 2


솔직히 말하면:

  L1 - 진짜 좋음
  - 161MB → 3.5MB, 실질적 가치
  - junk 제거하고 의미있는 것만 남김

  L2 - 괜찮은데 아쉬움
  - auto-l2가 LLM 없이 뽑아서 품질이 낮음
  - keywords가 ["현재", "상태", "브랜치"] 이런 식... 핵심 키워드가 아님
  - 제대로 하려면 LLM이 요약해야 하는데 그건 비용/시간 문제

  L3 - 솔직히 지금은 무의미함
  - 23개 L2가 전부 1개 concept로 병합됨
  - 같은 프로젝트니까 파일/키워드 overlap이 당연히 높음  
  - 결과: "name": "Base directory for this skill..." ← 이게 뭔 의미?
  - 차라리 memory.md 최근 50줄이 더 유용함

  L4 - 그냥 없는 거랑 같음
  - 자동화 미구현, 수동 입력만
  - facts.json에 10개 안되는 엔트리
  - "v8.3.0 예정" ← 언제?

  결론:
  L1만 실질적 가치. L2~L4는 설계는 좋은데 구현이 절반만  되어있어서, 지금 상태로는 기존 memory.md가 더 실용적임. hierarchical이라는 컨셉은 맞는데 각 layer가 제 역할을 못하고 있음.